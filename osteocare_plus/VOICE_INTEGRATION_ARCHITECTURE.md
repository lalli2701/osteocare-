# ğŸ¤ Multilingual Voice-Enabled Survey Architecture Guide

## ğŸ¯ System Overview

The voice system is built on a frontend-focused architecture where:

- **Frontend**: Handles TTS (Text-to-Speech), STT (Speech-to-Text), keyword mapping, answer confirmation
- **Backend**: Stores only language preference (`voice_enabled`, `preferred_language`) â€” never processes speech

Backend remains completely language and speech-neutral.

---

## ğŸ“ File Structure

```
lib/
â”œâ”€â”€ core/services/
â”‚   â”œâ”€â”€ voice_service.dart                 # TTS engine + voice script generation
â”‚   â”œâ”€â”€ speech_recognition_service.dart    # STT + keyword mapping per language
â”‚   â”œâ”€â”€ survey_service.dart                # Survey question loading (already implemented)
â”‚   â”œâ”€â”€ language_service.dart              # Language preference management
â”‚   â””â”€â”€ auth_service.dart                  # Authentication (existing)
â”‚
â”œâ”€â”€ features/survey/presentation/
â”‚   â”œâ”€â”€ survey_page.dart                   # Main survey UI (to integrate voice)
â”‚   â”œâ”€â”€ voice_question_widget.dart         # Reusable voice-enabled question widget
â”‚   â””â”€â”€ voice_confirmation_dialog.dart     # Confirmation dialog for voice answers
â”‚
â””â”€â”€ features/onboarding/presentation/
    â””â”€â”€ landing_page.dart                  # Already has floating voice controller
```

---

## ğŸ”‘ Key Components

### 1. **VoiceService** (voice_service.dart)

Manages **Text-to-Speech (TTS)** with dynamic language switching.

**Responsibilities:**
- Initialize and configure TTS engine
- Dynamically set TTS language (en-IN, hi-IN, te-IN)
- Generate voice scripts from question + language
- Handle speech control (play, stop, pause)

**Key Methods:**
```dart
// Change language for voice
await VoiceService().switchLanguage('hi');

// Build question voice script
final script = VoiceService().buildQuestionVoiceScript(
  currentIndex: 5,      // Question 5
  totalQuestions: 15,   // Out of 15
  questionText: translatedQuestion,
  options: ['Yes', 'No'],
);

// Speak the script
await VoiceService().speak(script);

// Stop speaking
await VoiceService().stop();
```

**Voice Script Format:**

English:
```
Question 5 of 15. Has a doctor ever told you that you have arthritis? You may answer by saying Yes or No.
```

Hindi:
```
15 à¤®à¥‡à¤‚ à¤¸à¥‡ 5à¤µà¤¾à¤ à¤ªà¥à¤°à¤¶à¥à¤¨à¥¤ à¤•à¥à¤¯à¤¾ à¤•à¤¿à¤¸à¥€ à¤¡à¥‰à¤•à¥à¤Ÿà¤° à¤¨à¥‡ à¤†à¤ªà¤•à¥‹ à¤†à¤°à¥à¤¥à¤°à¤¾à¤‡à¤Ÿà¤¿à¤¸ à¤¹à¥‹à¤¨à¥‡ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¦à¥€ à¤¹à¥ˆ? à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¹à¤¾à¤ à¤¯à¤¾ à¤¨à¤¹à¥€à¤‚ à¤•à¤¹à¥‡à¤‚à¥¤
```

Telugu:
```
15 à°²à±‹ 5à°µ à°ªà±à°°à°¶à±à°¨. à°®à±€à°•à± à°†à°°à±à°¥à°°à±ˆà°Ÿà°¿à°¸à± à°‰à°‚à°¦à°¨à°¿ à°¡à°¾à°•à±à°Ÿà°°à± à°à°ªà±à°ªà±à°¡à±ˆà°¨à°¾ à°šà±†à°ªà±à°ªà°¾à°°à±? à°¦à°¯à°šà±‡à°¸à°¿ à°…à°µà±à°¨à± à°²à±‡à°¦à°¾ à°•à°¾à°¦à± à°…à°¨à°¿ à°šà±†à°ªà±à°ªà°‚à°¡à°¿.
```

---

### 2. **SpeechRecognitionService** (speech_recognition_service.dart)

Manages **Speech-to-Text (STT)** with multilingual keyword mapping.

**Responsibilities:**
- Listen to user speech in selected language locale
- Map speech to Yes/No/Alternative/Unknown based on language keywords
- Extract numbers from speech (for age field)
- Never send raw transcript to backend

**Keyword Mapping by Language:**

**English:**
- Yes: yes, yeah, yup, sure, okay, ok, correct, right, affirmative
- No: no, nope, nah, negative, never, not, false

**Hindi:**
- Yes: haan, haa, ham, bilkul, theek, sahi
- No: nahi, nahin, na, bilkul nahi, kabhi nahi

**Telugu:**
- Yes: avunu, aavanu, oka, kosu
- No: kaadu, kadu, ledu, lenu

**Key Methods:**
```dart
// Set recognition language
await SpeechRecognitionService().setLanguage('hi');

// Start listening
await SpeechRecognitionService().startListening(
  onResult: (transcript) {
    // Process result
  },
  onError: () {
    // Handle error
  },
);

// Parse yes/no answer
final result = SpeechRecognitionService().parseYesNoAnswer(transcript);
// Returns: RecognitionResult.yes | .no | .alternative | .unknown

// Extract number (for age)
final age = SpeechRecognitionService().extractNumber(transcript);

// Get display text
final displayText = SpeechRecognitionService().getDisplayText(transcript, result);
```

---

## ğŸ¬ Complete Voice Flow Diagrams

### **App Startup Flow (Cold Launch)**

```
App Launch
  â†“
Check SharedPreferences for 'preferred_language'
  â†“
  â”œâ”€ Found â†’ Load stored language (e.g., 'hi')
  â”‚           Set app locale to 'hi'
  â”‚           Set VoiceService language to 'hi-IN'
  â”‚           Set SpeechRecognitionService to 'hi_IN'
  â”‚           Go to Splash
  â”‚
  â””â”€ Not Found â†’ Default to 'en'
                 Set app locale to 'en'
                 Set VoiceService to 'en-IN'
                 Set SpeechRecognitionService to 'en_IN'
                 Save 'en' to SharedPreferences
                 Go to Splash
```

### **After Login Flow**

```
Login Success
  â†“
Backend returns:
{
  "user": {...},
  "preferred_language": "telugu",
  "voice_enabled": true
}
  â†“
Frontend checks:
  If backend language â‰  local language
    â†’ Update context locale
    â†’ Update VoiceService
    â†’ Update SpeechRecognitionService
    â†’ Save to SharedPreferences
  Else
    â†’ Proceed as-is
  â†“
Go to Dashboard
```

### **Profile Language Change Flow**

```
User Opens Profile
  â†“
User Selects New Language (e.g., Hindi)
  â†“
Stop running TTS (if any)
Stop speech recognition (if active)
  â†“
Set VoiceService language to 'hi-IN'
Set SpeechRecognitionService to 'hi_IN'
  â†“
Update context locale to 'hi'
Save to SharedPreferences
  â†“
POST to backend: {"preferred_language": "hindi"}
  â†“
Reload current screen in new language
```

### **Survey Question Voice Reading Flow**

```
Survey Page Loads Question
  â†“
Question 5: "arthritis"
  â†“
Load translated question: "à¤•à¥à¤¯à¤¾ à¤•à¤¿à¤¸à¥€ à¤¡à¥‰à¤•à¥à¤Ÿà¤° à¤¨à¥‡..."
Load options: ["à¤¹à¤¾à¤", "à¤¨à¤¹à¥€à¤‚"]
  â†“
Get current language: 'hi'
Set VoiceService language: 'hi-IN'
Set SpeechRecognitionService language: 'hi_IN'
  â†“
Build voice script:
"15 à¤®à¥‡à¤‚ à¤¸à¥‡ 5à¤µà¤¾à¤ à¤ªà¥à¤°à¤¶à¥à¤¨à¥¤ à¤•à¥à¤¯à¤¾ à¤•à¤¿à¤¸à¥€ à¤¡à¥‰à¤•à¥à¤Ÿà¤° à¤¨à¥‡ à¤†à¤ªà¤•à¥‹ à¤†à¤°à¥à¤¥à¤°à¤¾à¤‡à¤Ÿà¤¿à¤¸ à¤¹à¥‹à¤¨à¥‡ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¦à¥€ à¤¹à¥ˆ? à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¹à¤¾à¤ à¤¯à¤¾ à¤¨à¤¹à¥€à¤‚ à¤•à¤¹à¥‡à¤‚à¥¤"
  â†“
Automatically read question via TTS
(or user can tap mic to read again)
  â†“
User taps Mic button
  â†“
SpeechRecognitionService starts listening in 'hi_IN' locale
  â†“
User speaks: "à¤¹à¤¾à¤"
  â†“
Transcript received: "à¤¹à¤¾à¤"
Parse with keyword map: RecognitionResult.yes
  â†“
Show confirmation dialog:
"à¤†à¤ªà¤¨à¥‡ à¤•à¤¹à¤¾: à¤¹à¤¾à¤à¥¤ à¤•à¥à¤¯à¤¾ à¤¯à¤¹ à¤¸à¤¹à¥€ à¤¹à¥ˆ?"
Buttons: [Confirm] [Retry]
  â†“
If Confirm:
  Store answer: {"arthritis": "Yes"}
  Move to next question
  
If Retry:
  Speak retry prompt: "à¤®à¥à¤à¥‡ à¤¸à¤®à¤ à¤¨à¤¹à¥€à¤‚ à¤†à¤¯à¤¾à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤"
  Restart listening
```

### **Landing Page Auto-Voice Flow**

```
Landing Page Renders
  â†“
Check voice_enabled preference (from backend after login)
  â†“
If voice_enabled == true:
  Get current language from SharedPreferences
  Set VoiceService language
  Auto-play overview in selected language
  Show Stop button
  
If voice_enabled == false:
  Show only Play button
  No auto-play
```

---

## ğŸš« Critical Rules

### **Never Do:**

âŒ Auto-submit after speech recognition
â†’ **Always show confirmation dialog before accepting**

âŒ Mix languages in same question
â†’ **Load and use one language at a time**

âŒ Send raw transcript to backend
â†’ **Send only structured answer: {"arthritis": "Yes"}**

âŒ Switch locale without stopping TTS/STT
â†’ **Stop, switch, reinitialize in order**

âŒ Trust voice input for complex data (height)
â†’ **Use touch input for height, voice for simple yes/no**

### **Always Do:**

âœ… Initialize VoiceService before playing audio
âœ… Initialize SpeechRecognitionService before listening
âœ… Check language before parsing keywords
âœ… Show confirmation before accepting answer
âœ… Handle speech recognition failure gracefully
âœ… Stop TTS when speech recognition starts
âœ… Match TTS locale with speech recognition locale

---

## ğŸ”§ Implementation Patterns

### **Pattern 1: Simple Yes/No Question with Voice**

```dart
class VoiceYesNoQuestion extends StatefulWidget {
  final SurveyQuestion question;
  final int currentIndex;
  final int totalQuestions;
  final Function(String answer) onAnswered;

  @override
  State<VoiceYesNoQuestion> createState() => _VoiceYesNoQuestionState();
}

class _VoiceYesNoQuestionState extends State<VoiceYesNoQuestion> {
  final VoiceService _voiceService = VoiceService();
  final SpeechRecognitionService _speechService = SpeechRecognitionService();
  bool _showVoiceUI = false;

  @override
  void initState() {
    super.initState();
    _initializeVoice();
  }

  Future<void> _initializeVoice() async {
    await _voiceService.initialize();
    final initialized = await _speechService.initialize();
    setState(() => _showVoiceUI = initialized);
  }

  Future<void> _readQuestion() async {
    final script = _voiceService.buildQuestionVoiceScript(
      widget.currentIndex,
      widget.totalQuestions,
      widget.question.question,
      widget.question.options,
    );
    await _voiceService.speak(script);
  }

  Future<void> _startListening() async {
    await _voiceService.stop(); // Stop question reading
    
    await _speechService.startListening(
      onResult: (transcript) {
        _handleVoiceResult(transcript);
      },
      onError: () {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(text: 'Could not recognize speech'),
        );
      },
    );
  }

  void _handleVoiceResult(String transcript) {
    final result = _speechService.parseYesNoAnswer(transcript);
    final displayText = _speechService.getDisplayText(transcript, result);

    if (result == RecognitionResult.unknown) {
      _showRetryDialog();
      return;
    }

    _showConfirmationDialog(displayText, result);
  }

  void _showConfirmationDialog(String userAnswer, RecognitionResult result) {
    showDialog(
      context: context,
      builder: (context) => AlertDialog(
        title: Text('Confirm Answer'),
        content: Text(_voiceService.getConfirmationPrompt(userAnswer)),
        actions: [
          TextButton(
            onPressed: () {
              Navigator.pop(context);
              widget.onAnswered(result == RecognitionResult.yes ? 'Yes' : 'No');
            },
            child: Text('Confirm'),
          ),
          TextButton(
            onPressed: () {
              Navigator.pop(context);
              _startListening(); // Retry
            },
            child: Text('Retry'),
          ),
        ],
      ),
    );
  }

  void _showRetryDialog() {
    final prompt = _voiceService.getRetryPrompt();
    _voiceService.speak(prompt).then((_) {
      Future.delayed(Duration(milliseconds: 500), _startListening);
    });
  }

  @override
  Widget build(BuildContext context) {
    return Column(
      children: [
        Text(widget.question.question),
        if (_showVoiceUI) ...[
          ElevatedButton(
            onPressed: _readQuestion,
            child: Icon(Icons.volume_up),
          ),
          ElevatedButton(
            onPressed: _startListening,
            child: Icon(Icons.mic),
          ),
        ],
      ],
    );
  }

  @override
  void dispose() {
    _voiceService.dispose();
    _speechService.dispose();
    super.dispose();
  }
}
```

---

## ğŸŒ Language Initialization Checklist

- [ ] VoiceService knows current language from SharedPreferences
- [ ] SpeechRecognitionService locale matches VoiceService language
- [ ] Survey questions loaded in correct language
- [ ] Keyword mapping loaded for current language
- [ ] Number extraction rules loaded for current language
- [ ] Voice scripts generated in current language

---

## ğŸ” Backend Language Rules

**Backend must store:**
- `voice_enabled` (boolean)
- `preferred_language` (string: 'english', 'hindi', 'telugu')

**Backend must NOT store:**
- Translated UI text
- Voice transcripts
- Speech recognition data

**Backend must NOT do:**
- Translate survey questions
- Translate risk levels
- Auto-generate translations

---

## âœ… Testing Checklist

- [ ] App launches with saved language preference
- [ ] TTS language matches app language
- [ ] Speech recognition locale matches app language
- [ ] Yes/No keywords recognized correctly in English
- [ ] Yes/No keywords recognized correctly in Hindi
- [ ] Yes/No keywords recognized correctly in Telugu
- [ ] Number extraction works for age (English)
- [ ] Confirmation dialog shown before accepting answer
- [ ] Retry works after failed recognition
- [ ] Language switch stops TTS/STT before changing
- [ ] No raw transcripts sent to backend
- [ ] Only structured answers sent to backend

---

## ğŸš€ Next Implementation Steps

1. **VoiceQuestionWidget** - Reusable component for voice-enabled questions
2. **Integrate with SurveyPage** - Add voice button to each question
3. **Voice Preference Toggle** - Allow users to enable/disable voice in settings
4. **Error Handling** - Graceful fallback when speech unavailable
5. **Performance** - Cache voice scripts to reduce TTS latency
6. **Testing** - Test multilingual recognition with native speakers

---

## ğŸ“Š Architecture Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FRONTEND (No Network Needed)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VoiceService (TTS)                             â”‚
â”‚  â””â”€ English: en-IN                              â”‚
â”‚  â””â”€ Hindi: hi-IN                                â”‚
â”‚  â””â”€ Telugu: te-IN                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SpeechRecognitionService (STT)                 â”‚
â”‚  â””â”€ Keyword mapping per language                â”‚
â”‚  â””â”€ Number extraction per language              â”‚
â”‚  â””â”€ Never sends raw transcript                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SurveyService                                  â”‚
â”‚  â””â”€ Loads questions in user's language          â”‚
â”‚  â””â”€ Provides translated question text           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LanguageService                                â”‚
â”‚  â””â”€ Manages language preference                 â”‚
â”‚  â””â”€ Syncs with backend                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“ (Only structured data)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BACKEND (Language Neutral)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Auth: Login, Signup                            â”‚
â”‚  Prefs: voice_enabled, preferred_language       â”‚
â”‚  Survey: Receives {"field": value}              â”‚
â”‚  Model: ML prediction (language independent)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This architecture ensures:
- âœ… Offline voice capability
- âœ… Fallback to text input
- âœ… Language-neutral model
- âœ… Privacy (no speech data stored)
- âœ… Performance (local processing)
